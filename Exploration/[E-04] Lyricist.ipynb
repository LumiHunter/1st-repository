{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae4e2d47",
   "metadata": {},
   "source": [
    "## 인공지능 작사가 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eea2e88",
   "metadata": {},
   "source": [
    "## 1. 데이터 읽어오기\n",
    "\n",
    "txt 파일들의 문장들을 줄 단위로 추출하여 'raw_corpus' 리스트에 담는다.(corpus는 '말뭉치'라는 뜻)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "162d6a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "txt_file_path = os.getenv('HOME') + '/aiffel/lyricist/data/lyrics/*'\n",
    "txt_list = glob.glob(txt_file_path)    # 여러개의 txt 파일을 읽어 리스트에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d64afbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples: \n",
      " [\"Now I've heard there was a secret chord\", 'That David played, and it pleased the Lord', \"But you don't really care for music, do you?\", 'It goes like this', 'The fourth, the fifth', 'The minor fall, the major lift', 'The baffled king composing Hallelujah Hallelujah', 'Hallelujah', 'Hallelujah', 'Hallelujah Your faith was strong but you needed proof']\n"
     ]
    }
   ],
   "source": [
    "raw_corpus = []\n",
    "\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:    # 읽기모드(\"r\")로 txt 파일 읽기\n",
    "        raw = f.read().splitlines()    # txt 파일을 줄 단위로 추출하기\n",
    "        raw_corpus.extend(raw)    # raw_corpus 리스트에 담기\n",
    "        \n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples: \\n\", raw_corpus[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c670a4e",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리: 문장 정제, 토큰화 및 벡터화\n",
    "\n",
    "띄어쓰기를 기준으로 문장의 단어들을 정의하기에 앞서, 대소문자 통일/문장부호 분리/반복되거나 문장 양 옆에 붙은 공백 삭제/특수문자 삭제/문장의 시작과 끝을 정의하는 '\\<start\\>'와 '\\<end\\>' 삽입 등의 정제 과정을 수행할 함수를 정의한다.\n",
    "\n",
    "\n",
    "각각의 단어들을 텐서플로우가 제공하는 tf.keras.preprocessing.text.Tokenizer 패키지를 통해 숫자로 변환(벡터화(vercorize), 여기서 변환된 숫자를 '텐서(tensor)'라고 칭한다)하고, 각 단어들과 텐서를 매칭한 단어 사전을 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03ebe1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> now i ve heard there was a secret chord <end>\n",
      "<start> that david played , and it pleased the lord <end>\n",
      "<start> but you don t really care for music , do you ? <end>\n",
      "<start> it goes like this <end>\n",
      "<start> the fourth , the fifth <end>\n",
      "<start> the minor fall , the major lift <end>\n",
      "<start> the baffled king composing hallelujah hallelujah <end>\n",
      "<start> hallelujah <end>\n",
      "<start> hallelujah <end>\n",
      "<start> hallelujah your faith was strong but you needed proof <end>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() # 모두 소문자로 바꾸기\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 특수문자 양쪽에 공백을 넣기\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 공백들은 하나의 공백으로 바꾸기\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) #a-zA-Z?.!,¿가 아닌 모든 문자는 공백으로 바꾸기 \n",
    "    sentence = sentence.strip() # 양쪽 공백을 지우기\n",
    "    sentence = '<start> ' + sentence + ' <end>' # 시작과 끝에 마크 달기\n",
    "    return sentence\n",
    "\n",
    "for i in range(10):\n",
    "    print(preprocess_sentence(raw_corpus[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8bcbd5",
   "metadata": {},
   "source": [
    "* 문장 전처리 함수 preprocess_sentence(sentence) 생성\n",
    "  * strip(): 괄호 안에 지정한 문자(열)을 삭제함. 괄호를 비워두면 문장의 앞 뒤에 있는 공백을 삭제함\n",
    "  * re.sub(찾을 패턴(정규 표현식), 치환할 문자(열), 대상 문자열): 대상 문자열에서 지정된 패턴을 만족하는 부분을 지정된 문자(열)로 치환함\n",
    "\n",
    "\n",
    "* 정규 표현식이란 특정한 규칙을 가진 문자열의 집합을 표현하는 데 사용하는 일종의 형식 언어이다. 파이썬에서 정규 표현식을 사용할 때는 내장 모듈인 re를 import해야 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e6fe8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> now i ve heard there was a secret chord <end>',\n",
       " '<start> that david played , and it pleased the lord <end>',\n",
       " '<start> but you don t really care for music , do you ? <end>',\n",
       " '<start> it goes like this <end>',\n",
       " '<start> the fourth , the fifth <end>',\n",
       " '<start> the minor fall , the major lift <end>',\n",
       " '<start> the baffled king composing hallelujah hallelujah <end>',\n",
       " '<start> hallelujah <end>',\n",
       " '<start> hallelujah <end>',\n",
       " '<start> hallelujah your faith was strong but you needed proof <end>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    if len(preprocessed_sentence.split()) > 15: continue\n",
    "    corpus.append(preprocessed_sentence)\n",
    "\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf574f81",
   "metadata": {},
   "source": [
    "* raw_corpus에 있는 문장들을 모두 정제하여 입력 데이터 'corpus' 리스트에 담는다.\n",
    "* 너무 긴 문장은 토큰화 했을 때 비교적 짧은 문장에 지나치게 많은 패딩(padding)을 갖게 하므로, '\\<start\\>'와 '\\<end\\>'를 포함하여 단어의 수가 15개를 넘는 문장은 제외하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b0fc3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2   50    4 ...    0    0    0]\n",
      " [   2   15 2971 ...    0    0    0]\n",
      " [   2   33    7 ...   46    3    0]\n",
      " ...\n",
      " [   2    4  117 ...    0    0    0]\n",
      " [   2  258  195 ...   12    3    0]\n",
      " [   2    7   34 ...    0    0    0]] \n",
      " <keras_preprocessing.text.Tokenizer object at 0x7f77dccee190>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def tokenize(corpus):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=15000,\n",
    "        filters=' ',\n",
    "        oov_token=\"<unk>\"  \n",
    "    )    #15000단어까지 저장하는 tokenizer 생성\n",
    "\n",
    "    tokenizer.fit_on_texts(corpus)    # corpus를 기반으로 tokenizer 내부 단어장 생성\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)    # 단어들을 숫자로 변환(corpus를 tensor로 변환)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "    # 입력 데이터의 시퀀스 길이를 만추어, 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙임\n",
    "    \n",
    "    print(tensor, '\\n', tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec32cf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : i\n",
      "5 : ,\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n"
     ]
    }
   ],
   "source": [
    "# tokenizer 내부 단어장 인덱스와 단어 확인\n",
    "\n",
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 10: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c98daa",
   "metadata": {},
   "source": [
    "## 3. 평가 데이터 분할과 데이터셋 객체 생성\n",
    "\n",
    "모델의 입력이 되는 문장을 Source Sentence, 출력 문장(모델이 맞추어야 할 '정답' 역할)을 Target Sentence라고 한다. 타겟 문장은 첫 단어 '\\<start\\>'를 입력 받은 다음 생성될 문장에 해당하므로, 모델을 학습시킬 때는 첫번째 토큰을 잘라낸 것을 타겟 문장(dec_train)으로 지정한다. 반대로 소스 문장(enc_train)은 마지막 토큰을 잘라낸 것으로 지정한다.\n",
    "\n",
    "데이터 분할이 끝난 다음, 모델을 학습시키기 위해 데이터셋 객체를 생성한다. 텐서플로우에서 제공하는 기능을 이용해 텐서로 생성된 데이터들의  tf.data.Dataset 객체를 생성하면 데이터 입력 시 파이프라인을 통한 속도 개선 등의 이점을 누릴 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d019ee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(tensor[:,:-1], tensor[:,1:], test_size = 0.2, random_state = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6157436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (133863, 14)\n",
      "Target Train: (133863, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"Source Train:\", enc_train.shape)\n",
    "print(\"Target Train:\", dec_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ef52962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2 2020  363 2020   73 1155   10 7025    3    0    0    0    0    0]\n",
      "[2020  363 2020   73 1155   10 7025    3    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(enc_train[0])\n",
    "print(dec_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eb27097",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(enc_train)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(enc_train) // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1    # tokenizer가 구축한 단어사전에 <pad> 추가\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaff842",
   "metadata": {},
   "source": [
    "* 텐서 형태로 생성되어 있던 데이터에 tf.data.Dataset.from_tensor_slices() 메소드를 이용해 tf.data.Dataset 객체를 형성한다.\n",
    "* Batch size란 머신러닝에서 한번 파라미터가 업데이트 될 때 이용되는 학습 데이터의 수를 의미한다. [용어설명 참고](https://radiopaedia.org/articles/batch-size-machine-learning) 일종의 학습 단위의 역할을 하는 수치로 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7fe0ad",
   "metadata": {},
   "source": [
    "## 4. 모델 생성과 학습시키기\n",
    "\n",
    "모델은 Embedding 레이어->2개의 LSTM 레이어->Dense 레이어로 구성되어 있다.\n",
    "\n",
    "Embedding 레이어에서는 단어들의 인덱스를 워드 벡터로 변환하여 단어를 추상적으로 표현한다. 2개의 LSTM 레이어를 거치며 모델은 문장을 순차적으로 읽으며 단어 간의 연관성을 분석하고, Dense 레이어에서는 그 결과를 바탕으로 다음에 생성할 단어를 결정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c68a013",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):    # tf.keras.Model의 서브클래스임\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 256   # 단어가 추상적으로 표현되는 크기\n",
    "hidden_size = 1024    # hidden layer 깊이\n",
    "\n",
    "lyricist = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74f8be25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 15001), dtype=float32, numpy=\n",
       "array([[[ 2.30684891e-05, -7.96226959e-05, -1.82434960e-04, ...,\n",
       "          8.52816302e-05, -1.12183452e-05,  1.61298231e-05],\n",
       "        [ 1.79620649e-04, -1.59299234e-04, -3.24988505e-04, ...,\n",
       "          9.01273233e-05,  1.08611093e-04, -2.51433492e-04],\n",
       "        [ 2.63709167e-04, -1.32490619e-04, -3.35847784e-04, ...,\n",
       "          7.67944803e-05,  2.43297909e-04, -4.93796426e-04],\n",
       "        ...,\n",
       "        [ 1.11505250e-03,  1.16501143e-03,  5.43273112e-04, ...,\n",
       "         -1.60668697e-03,  1.01376360e-03, -6.46587359e-05],\n",
       "        [ 1.23739755e-03,  1.22543436e-03,  5.82762179e-04, ...,\n",
       "         -1.76089141e-03,  1.08829734e-03,  7.07973595e-05],\n",
       "        [ 1.35261496e-03,  1.26741396e-03,  6.07508060e-04, ...,\n",
       "         -1.88889750e-03,  1.16379431e-03,  1.98678448e-04]],\n",
       "\n",
       "       [[ 2.30684891e-05, -7.96226959e-05, -1.82434960e-04, ...,\n",
       "          8.52816302e-05, -1.12183452e-05,  1.61298231e-05],\n",
       "        [-2.40670313e-04, -1.22190235e-04, -4.03542217e-04, ...,\n",
       "          3.77231103e-04, -1.23300370e-05,  9.12392861e-05],\n",
       "        [-4.22060606e-04, -2.93185749e-05, -4.35734139e-04, ...,\n",
       "          6.35183067e-04, -5.64606125e-05,  2.68391450e-04],\n",
       "        ...,\n",
       "        [ 6.09163661e-04,  7.62935204e-04,  1.00202575e-04, ...,\n",
       "         -9.23788408e-04,  1.14627380e-03, -5.84968438e-05],\n",
       "        [ 7.45596713e-04,  8.70245858e-04,  2.07421515e-04, ...,\n",
       "         -1.20255433e-03,  1.17832527e-03,  4.07196640e-05],\n",
       "        [ 8.86063674e-04,  9.62766760e-04,  2.98067665e-04, ...,\n",
       "         -1.44618074e-03,  1.21051434e-03,  1.45097627e-04]],\n",
       "\n",
       "       [[ 2.30684891e-05, -7.96226959e-05, -1.82434960e-04, ...,\n",
       "          8.52816302e-05, -1.12183452e-05,  1.61298231e-05],\n",
       "        [ 5.79045627e-06, -2.40134650e-05, -2.40441179e-04, ...,\n",
       "          5.58027350e-05, -1.28910324e-04,  2.38246954e-04],\n",
       "        [ 8.64886242e-05,  3.71372735e-05, -3.29857779e-04, ...,\n",
       "          1.19402081e-04,  1.97767258e-05,  2.52026162e-04],\n",
       "        ...,\n",
       "        [ 7.14114460e-04,  6.93716516e-04,  4.91023238e-04, ...,\n",
       "         -3.90412344e-04,  5.38695196e-04, -1.43257610e-03],\n",
       "        [ 7.54179491e-04,  8.87505012e-04,  5.74620673e-04, ...,\n",
       "         -6.54485717e-04,  6.19203434e-04, -1.30580936e-03],\n",
       "        [ 8.18117522e-04,  1.05202803e-03,  6.37472956e-04, ...,\n",
       "         -9.16439225e-04,  6.95885450e-04, -1.13870762e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 2.30684891e-05, -7.96226959e-05, -1.82434960e-04, ...,\n",
       "          8.52816302e-05, -1.12183452e-05,  1.61298231e-05],\n",
       "        [-6.27800619e-05, -1.38388696e-05, -2.66830524e-04, ...,\n",
       "          3.22264008e-04, -5.24152711e-05, -2.55956431e-04],\n",
       "        [-1.82137519e-04, -3.16685546e-05, -1.80647447e-04, ...,\n",
       "          3.72903014e-04, -1.50587250e-04, -2.92818557e-04],\n",
       "        ...,\n",
       "        [ 4.36940376e-04, -7.88849022e-04,  4.22299374e-04, ...,\n",
       "          8.21261128e-05, -3.50006914e-04,  8.44048991e-05],\n",
       "        [ 6.31220930e-04, -9.45459353e-04,  4.46021761e-04, ...,\n",
       "         -5.32504491e-05, -2.18067828e-04,  1.02647478e-04],\n",
       "        [ 9.21111437e-04, -9.75175819e-04,  3.80667101e-04, ...,\n",
       "         -2.00797862e-04,  1.76684534e-05, -1.78087619e-04]],\n",
       "\n",
       "       [[ 2.30684891e-05, -7.96226959e-05, -1.82434960e-04, ...,\n",
       "          8.52816302e-05, -1.12183452e-05,  1.61298231e-05],\n",
       "        [ 2.47338729e-04, -2.29025361e-04, -1.95480621e-04, ...,\n",
       "          2.82327528e-04, -2.98616615e-05, -5.01082695e-06],\n",
       "        [ 3.68939276e-04, -3.70474067e-04, -1.20190480e-05, ...,\n",
       "          3.73096904e-04, -8.49824646e-05,  1.89678685e-04],\n",
       "        ...,\n",
       "        [ 4.36836155e-04, -1.23961573e-03,  2.32051374e-04, ...,\n",
       "          8.51604214e-04, -2.39677378e-04,  1.77355949e-04],\n",
       "        [ 5.25005569e-04, -1.26833643e-03,  1.26472500e-04, ...,\n",
       "          7.28633371e-04,  3.13489218e-05, -1.58924682e-04],\n",
       "        [ 5.44431619e-04, -1.14625611e-03,  7.21316683e-05, ...,\n",
       "          5.80193650e-04,  2.91795499e-04, -4.73811582e-04]],\n",
       "\n",
       "       [[ 2.30684891e-05, -7.96226959e-05, -1.82434960e-04, ...,\n",
       "          8.52816302e-05, -1.12183452e-05,  1.61298231e-05],\n",
       "        [-3.45263659e-04, -2.60468019e-04, -2.90654454e-04, ...,\n",
       "          1.17594805e-04, -1.74643836e-04, -2.99490930e-05],\n",
       "        [-4.58780036e-04, -5.01500850e-04, -1.79818380e-04, ...,\n",
       "          8.39280401e-05, -4.77106078e-04,  4.06485226e-04],\n",
       "        ...,\n",
       "        [-3.98057105e-04, -5.46674710e-04,  1.00162148e-03, ...,\n",
       "          7.29313353e-04, -4.32729779e-04, -1.25129998e-03],\n",
       "        [-2.41276561e-04, -3.20186460e-04,  1.11650757e-03, ...,\n",
       "          5.91576798e-04, -2.04543932e-04, -1.55445409e-03],\n",
       "        [-9.26332286e-05, -6.85551786e-05,  1.21030491e-03, ...,\n",
       "          3.96587653e-04,  1.40429547e-05, -1.72458787e-03]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modal 'lyricist'가 제대로 build 될 수 있도록 데이터셋에서 한 배치를 가져와 호출\n",
    "for src_sample, tat_sample in dataset.take(1): break\n",
    "    \n",
    "lyricist(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6034afeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  3840256   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  15376025  \n",
      "=================================================================\n",
      "Total params: 32,855,961\n",
      "Trainable params: 32,855,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lyricist.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89c4a376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "522/522 [==============================] - 94s 171ms/step - loss: 3.3279\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 97s 186ms/step - loss: 2.8702\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 97s 186ms/step - loss: 2.7198\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 98s 187ms/step - loss: 2.6065\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 98s 187ms/step - loss: 2.5101\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 98s 186ms/step - loss: 2.4244\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 97s 186ms/step - loss: 2.3450\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 98s 186ms/step - loss: 2.2708\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 97s 186ms/step - loss: 2.2004\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 97s 186ms/step - loss: 2.1339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f775007b3a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "lyricist.compile(loss=loss, optimizer=optimizer)\n",
    "lyricist.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2141d6fc",
   "metadata": {},
   "source": [
    "## 5. 문장 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "419b336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    while True:\n",
    "        predict = model(test_tensor) \n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72e6b16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you so much <end> '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist, tokenizer, init_sentence=\"<start> i love\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b8bb6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> he s a sportsman and a shepherd <end> '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist, tokenizer, init_sentence=\"<start> he\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30481201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> she s a sportsman and a shepherd <end> '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist, tokenizer, init_sentence=\"<start> she\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5147704e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> you re the one that i m in <end> '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist, tokenizer, init_sentence=\"<start> you\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79397e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> we re gonna have to be the same <end> '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist, tokenizer, init_sentence=\"<start> we\", max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac475f3",
   "metadata": {},
   "source": [
    "* init_sentence에 따라 부자연스럽게 종결된 문장도 있고 중복된 문장도 있지만, 주어가 바뀜에 따라 be동사를 바꾸고, 동사 뒤에는 명사나 부사가 오는 등 기본적인 영어 문법에 맞춰 문장을 생성하고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e318dfdc",
   "metadata": {},
   "source": [
    "## 6. 하이퍼파라미터 바꿔보기\n",
    " \n",
    "RNN(순환신경망) 구조에서 입력층과 출력층 사이의 은닉층(hidden layer)은 한 계층을 지날 때 마다 각기 예측한 값을 다음 계층에 넘기며 학습을 진행한다. 그 과정에서 모델은 단어와 단어 사이의 규칙을 도출하게 된다.\n",
    "\n",
    "embedding_size를 단어를 추상적으로 표현된 정도라고 한다면, 단어의 추상적인 정도가 높아질 수록 규칙을 도출하는 과정이 길어질 것이라고 예상하는 것이 자연스럽다. 이에 hidden_size는 바꾸지 않고, embedding_size를 조절하며 결과를 비교해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9538b566",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "hidden_size = 1024\n",
    "\n",
    "lyricist_2 = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e01509c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      multiple                  1920128   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                multiple                  4722688   \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  15376025  \n",
      "=================================================================\n",
      "Total params: 30,411,545\n",
      "Trainable params: 30,411,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for src_sample, tat_sample in dataset.take(1): break\n",
    "    \n",
    "lyricist_2(src_sample)\n",
    "lyricist_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cfc34c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "522/522 [==============================] - 98s 185ms/step - loss: 3.1847\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 96s 183ms/step - loss: 2.7731\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 96s 184ms/step - loss: 2.6324\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 96s 184ms/step - loss: 2.5167\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 96s 183ms/step - loss: 2.4086\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 96s 183ms/step - loss: 2.3073\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 96s 183ms/step - loss: 2.2113\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 96s 184ms/step - loss: 2.1202\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 96s 183ms/step - loss: 2.0317\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 96s 184ms/step - loss: 1.9465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f76c9334220>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyricist_2.compile(loss=loss, optimizer=optimizer)\n",
    "lyricist_2.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ecaa30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you <end> '"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist_2, tokenizer, init_sentence=\"<start> i love\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd056cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> he s got a multi bonnet <end> '"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist_2, tokenizer, init_sentence=\"<start> he\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8e07a617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> she s got a multi garden <end> '"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist_2, tokenizer, init_sentence=\"<start> she\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b0e7b6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> you re the only one i want <end> '"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist_2, tokenizer, init_sentence=\"<start> you\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6fba4696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> we re gonna have to serve somebody <end> '"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist_2, tokenizer, init_sentence=\"<start> we\", max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5f36a9",
   "metadata": {},
   "source": [
    "* embedding size를 절반으로 줄인 결과 파라미터는 30,411,545개로 다소 줄어들었다.\n",
    "* validation loss가 약 1.9로 줄어들었다. embedding size를 줄이는 것이 '정답률'을 낮추지는 않는 것으로 보이나, 다소 어색한 단어 조합을 출력하고 있다.('multi bonnet', 'multi garden')\n",
    "* epoch 당 소요시간은 거의 줄지 않았다. embedding size를 줄여 단어들의 추상적인 정도가 줄어들었다고 해서 학습시간이 크게 줄지는 않는 것으로 보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a2521f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 512\n",
    "hidden_size = 1024   \n",
    "lyricist_3 = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ba4e112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      multiple                  7680512   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                multiple                  6295552   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  15376025  \n",
      "=================================================================\n",
      "Total params: 37,744,793\n",
      "Trainable params: 37,744,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for src_sample, tat_sample in dataset.take(1): break\n",
    "    \n",
    "lyricist_3(src_sample)\n",
    "lyricist_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4856abc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "522/522 [==============================] - 104s 195ms/step - loss: 3.2980\n",
      "Epoch 2/10\n",
      "522/522 [==============================] - 103s 197ms/step - loss: 2.8817\n",
      "Epoch 3/10\n",
      "522/522 [==============================] - 103s 197ms/step - loss: 2.7028\n",
      "Epoch 4/10\n",
      "522/522 [==============================] - 103s 198ms/step - loss: 2.5672\n",
      "Epoch 5/10\n",
      "522/522 [==============================] - 103s 198ms/step - loss: 2.4453\n",
      "Epoch 6/10\n",
      "522/522 [==============================] - 103s 197ms/step - loss: 2.3306\n",
      "Epoch 7/10\n",
      "522/522 [==============================] - 103s 198ms/step - loss: 2.2196\n",
      "Epoch 8/10\n",
      "522/522 [==============================] - 103s 198ms/step - loss: 2.1135\n",
      "Epoch 9/10\n",
      "522/522 [==============================] - 103s 197ms/step - loss: 2.0111\n",
      "Epoch 10/10\n",
      "522/522 [==============================] - 103s 198ms/step - loss: 1.9133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f76c97c9940>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyricist_3.compile(loss=loss, optimizer=optimizer)\n",
    "lyricist_3.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "895c023e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you , i love you <end> '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist_3, tokenizer, init_sentence=\"<start> i love\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c5d220e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> he s got a hungry heart <end> '"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist_3, tokenizer, init_sentence=\"<start> he\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6edea99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> she s got me runnin round and round <end> '"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist_3, tokenizer, init_sentence=\"<start> she\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "242c9a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> you re the only one i want to be <end> '"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist_3, tokenizer, init_sentence=\"<start> you\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "befab5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> we re gonna have to fight <end> '"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist_3, tokenizer, init_sentence=\"<start> we\", max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8f96e1",
   "metadata": {},
   "source": [
    "* embedding size를 두배로 늘린 결과 파라미터는 37,744,793개로 늘었다..\n",
    "* validation loss가 약 1.9까지 내려갔고, init_sentence별로 중복된 문장 또는 단어가 나타나지 않으며, 맥락상 크게 어색하지 않다.\n",
    "* epoch 당 소요시간은 100초 대로 늘었다. 단어들의 추상적인 정도가 일정 수준 이상으로 높아지면 학습시간에도 영향이 있는 것으로 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14f580e",
   "metadata": {},
   "source": [
    "## 회고\n",
    "\n",
    "* 알게 된 점\n",
    "  * 단어는 단어 간의 사이에서 의미와 맥락을 가진다. 이는 자연어 처리에서는 의미 벡터(추상화)와 확률분포로 나타난다.이를 구현한 모델에서는 각 하이퍼파라미터를 무작정 높인다는 것이 효과적이지 않을 수도 있다. \n",
    "  \n",
    "\n",
    "* 궁금한 점 \n",
    "  * 문장 데이터 전처리 시 단어의 수가 15개를 넘는 문장은 제외했는데, 만약 그보다 더 긴 문장을 허용한다면 모델은 더 긴 문장을 작성할 수 있을까?\n",
    "  * tokenizer 내 저장할 단어의 수를 더 늘리면 처리해야 할 단어간의 관계, 의미의 폭이 더 넓어지니 validation loss를 낮추기 위해 embedding size나 hidden size를 수정해야 할까? 아니면 차이가 없을까?\n",
    "  \n",
    "\n",
    "* 모호한 점\n",
    "  * 노드 내용에서는 embedding size와 hidden size를 각각 2의 8제곱, 2의 10제곱으로 제시했었는데, 하이퍼파라미터로 2의 거듭제곱 수를 사용하는 것에 이점이 있는지 궁금하다.\n",
    "  * 자연어 처리를 위한 딥러닝에서 하이퍼파라미터는 문장의 자연스러운 맥락을 결정짓고, 그러므로 적절한 값을 찾는 것이 무척 중요한 과제일 듯 하다. 하지만 문장의 '자연스러운 맥락'을 어떻게 정의하고, 어떤 원칙으로 하이퍼파라미터를 조정해야 할까?\n",
    "\n",
    "\n",
    "* 다짐: 텐서라는 개념은 분명 학부 전공에서 접해본 적이 있는 개념인데... 잘 사용해본 적이 없어서 기억이 가물가물하다. 단어를 '차원화'하여 사용하는 자연어 처리 공부를 위해서는 꼭 다시 알아두어야 할 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b7f46a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
