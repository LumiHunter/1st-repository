{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "933b481c",
   "metadata": {},
   "source": [
    "## Scikit -Learn 패키지를 이용한 분류 문제 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94675b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351146e6",
   "metadata": {},
   "source": [
    "## 1. load_digits: 손글씨 분류\n",
    "\n",
    "### 1) 데이터 탐색\n",
    "\n",
    "* load_digit() 메서드로 불러온 데이터는 64개의 feature를 가진 1797개의 샘플을 보유하고 있다.\n",
    "* 이 데이터는 0에서 9까지의 숫자의 손글씨 이미지 데이터로서, 하나의 샘플은 8×8 = 64픽셀로 이루어져 있다. 각 픽셀은 64개의 feature로 저장되어 있다.\n",
    "* 이 중 약 20%에 해당하는 360개 샘플을 테스트 데이터로 무작위 분리하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94200ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec2e421c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91c24f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d020094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "164c9801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c7a48e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = digits.data \n",
    "label = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4523fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n"
     ]
    }
   ],
   "source": [
    "print(digits.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5506370d",
   "metadata": {},
   "source": [
    "feature_names는 **`이미지 샘플들이 (0,0) 부터 (7,7) 까지 정렬된 픽셀의 배열로써 존재`하며, digits 데이터의 feature 자체가 각 이미지를 이루고 있는 픽셀 값 하나하나로 구성되어 있음을 시사한다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50f76d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb70c44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e781375",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1437, 64)\n",
      "(360, 64)\n",
      "(1437,)\n",
      "(360,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature, label, test_size = 0.2, random_state = 50)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfb8476d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  1\n",
       "2  2\n",
       "3  3\n",
       "4  4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(digits.target)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3a9924b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    183\n",
      "1    182\n",
      "5    182\n",
      "4    181\n",
      "6    181\n",
      "9    180\n",
      "7    179\n",
      "0    178\n",
      "2    177\n",
      "8    174\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[0].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c28d1a8",
   "metadata": {},
   "source": [
    "데이터가 균등하게 분포하고 있는지 target을 Dataframe화 하여 알아본 결과, **`1797개 샘플 내 10개의 숫자는 약 10% 씩으로 균등하게 분포`**하고 있음을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23acca3f",
   "metadata": {},
   "source": [
    "### 2) 다양한 모델로 학습, 비교해보기\n",
    "\n",
    "* digits 데이터는 분류하고자 하는 target이 충분히 각 클래스에 균등하게 분포하고 있으므로 평가지표로 accuracy를 택했다.\n",
    "* Decision Tree가 가장 낮은 accuracy를, Support Vector Machine이 가장 높은 accuracy를 보였다.\n",
    "  * digits 데이터는 feature가 64개이므로, decision tree를 만들었을 때 depth가 다소 깊어져 학습데이터에 대해 overfitting이 발생하여 accuracy가 떨어졌을 가능성이 높다.\n",
    "* [scikit learn tutorial](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)에 의하면 분류 문제 중 데이터 샘플의 갯수가 약 십만개 보다 적을 경우에는 Linear SVC 모델을 쓰는 것이 적합하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a391a51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<Classification Report of Descision Tree>\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96        41\n",
      "           1       0.94      0.76      0.84        42\n",
      "           2       0.91      0.87      0.89        45\n",
      "           3       0.81      0.76      0.79        29\n",
      "           4       0.76      0.94      0.84        31\n",
      "           5       0.79      0.87      0.83        31\n",
      "           6       0.97      0.87      0.92        38\n",
      "           7       0.86      0.89      0.87        35\n",
      "           8       0.57      0.71      0.63        28\n",
      "           9       0.82      0.80      0.81        40\n",
      "\n",
      "    accuracy                           0.84       360\n",
      "   macro avg       0.84      0.84      0.84       360\n",
      "weighted avg       0.86      0.84      0.85       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Tree = DecisionTreeClassifier(random_state = 50)\n",
    "Tree.fit(X_train, y_train)\n",
    "y_pred = Tree.predict(X_test)\n",
    "print(\"\\t<Classification Report of Descision Tree>\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1319c0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<Classification Report of Ramdom Forest>\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        41\n",
      "           1       0.95      1.00      0.98        42\n",
      "           2       0.98      1.00      0.99        45\n",
      "           3       0.93      0.90      0.91        29\n",
      "           4       0.97      1.00      0.98        31\n",
      "           5       0.97      0.97      0.97        31\n",
      "           6       1.00      0.97      0.99        38\n",
      "           7       0.94      0.97      0.96        35\n",
      "           8       0.93      0.89      0.91        28\n",
      "           9       0.97      0.93      0.95        40\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Forest = RandomForestClassifier(random_state = 50)\n",
    "Forest.fit(X_train, y_train)\n",
    "y_pred = Forest.predict(X_test)\n",
    "print(\"\\t<Classification Report of Ramdom Forest>\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2138e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<Classification Report of Support Vector Machine>\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        41\n",
      "           1       0.98      1.00      0.99        42\n",
      "           2       1.00      1.00      1.00        45\n",
      "           3       1.00      0.97      0.98        29\n",
      "           4       0.97      1.00      0.98        31\n",
      "           5       0.97      0.97      0.97        31\n",
      "           6       1.00      1.00      1.00        38\n",
      "           7       1.00      0.97      0.99        35\n",
      "           8       1.00      0.96      0.98        28\n",
      "           9       0.95      1.00      0.98        40\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.98      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM = svm.SVC()\n",
    "SVM.fit(X_train, y_train)\n",
    "y_pred = SVM.predict(X_test)\n",
    "print(\"\\t<Classification Report of Support Vector Machine>\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "416485eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<Classification Report of Stochastic Gradient Descent Classifier>\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        41\n",
      "           1       0.87      0.93      0.90        42\n",
      "           2       1.00      1.00      1.00        45\n",
      "           3       1.00      0.86      0.93        29\n",
      "           4       1.00      0.97      0.98        31\n",
      "           5       1.00      0.94      0.97        31\n",
      "           6       1.00      1.00      1.00        38\n",
      "           7       0.94      0.97      0.96        35\n",
      "           8       0.76      0.93      0.84        28\n",
      "           9       0.92      0.88      0.90        40\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.94      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SGD = SGDClassifier()\n",
    "SGD.fit(X_train, y_train)\n",
    "y_pred = SGD.predict(X_test)\n",
    "print(\"\\t<Classification Report of Stochastic Gradient Descent Classifier>\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08ab2b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<Classification Report of Logistic Regression>\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        41\n",
      "           1       0.95      0.95      0.95        42\n",
      "           2       1.00      1.00      1.00        45\n",
      "           3       0.96      0.93      0.95        29\n",
      "           4       0.94      0.97      0.95        31\n",
      "           5       1.00      0.90      0.95        31\n",
      "           6       1.00      1.00      1.00        38\n",
      "           7       1.00      0.94      0.97        35\n",
      "           8       0.96      0.96      0.96        28\n",
      "           9       0.89      1.00      0.94        40\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "y_pred = LR.predict(X_test)\n",
    "print(\"\\t<Classification Report of Logistic Regression>\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "184212f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAADrElEQVR4nO3dQVEjYRRG0c4UAoKDOAAJkRAHRAJSggOkIAEJkdAOegxQM6t5fQfOWSaLLyxu/VVs3mHbtgXo+bX3DwC+Jk6IEidEiROixAlRD3/5/lv+K/d6vY7uPT8/j229v7+PbZ3P57Gt2+02trWDw1cfejkhSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQdfjL8dxveY7h9fV1dG9d17Gt+/0+tvX5+fktt5ZlWU6n0+SccwzwPxEnRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRD3s/QP2cLlcRvdut9vY1uQZgePxOLY1fB4hwcsJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFC1GHbtj99/8cv/1fruo7uPT4+jm29vLyMbU3egJm8y7KDw1cfejkhSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQ9bD3D9jD5XIZ3Xt6ehrbul6vY1vf/ETC7rycECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiPqR5ximfXx8jG1NnpqY/Lt+Ii8nRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTojLnGNZ1Hds6nU5jW8sy+7fd7/exLf4tLydEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlRmVspx+NxbGvydsmyLMv5fB7bent7G9vi3/JyQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IeqwbdvevwH4gpcTosQJUeKEKHFClDghSpwQ9RsAYEKrBEy+cQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값: 9 | 실제값: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAADm0lEQVR4nO3dQVEjURhG0c4Ue3BAHIAEJCAFCUggEqIEDTgABcRBj4FU2Mz8fYFzlunF11XJrVeVzdut67oAPX+2fgHgPHFClDghSpwQJU6Iuvriub9y/4Gnp6exrcPhMLb1+vo6tvXw8DC2tYHduQ+dnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlToj66jqGMafTaWzr+fl5bGtZZq9IuLu7G9va7/djW7+RkxOixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlRmesY7u/vx7Y+Pj7GtpZlWW5vb8e2Hh8fx7Zcx/B/OTkhSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IunhXyul0GnqN2a3r6+uxrWVZlsPhMLY1eVfK5Hf28vIytlXh5IQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocULUxesYbm5uhl5jWY7H49jW5JUFW+xNmfx9/EZOTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0Tt1nW99Pziw+/q/f19dG/yOoa3t7exrc/Pz7GtH371w+7ch05OiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRF1t/QJb2O/3P3pvyg+/ImFzTk6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocULUbl3Xrd8BOMPJCVHihChxQpQ4IUqcECVOiPoLBJo5ovqnmyAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값: 5 | 실제값: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAADpUlEQVR4nO3dQVEjYRRG0Z+pEYCEOAALKEACkRApOAAcICE4iYREQcZAatjMvFzgnGV68fXmVldl827O5/MCen5d+wWAy8QJUeKEKHFClDgh6vcnz8f+yj0ej1NTa7fbjW2ttdb7+/vY1ul0Gtu6u7sb23p9fR3bWmut+/v7ybmbSz/6ckKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCHqs3MMYz4+Psa29vv92NZaa729vY3uTXl6ehrbmjxpsdb4OYaLfDkhSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQlTnH8Pj4+C23ph0Oh2u/wn+x2Wyu/QrjfDkhSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IytxK4d94fn4e2zqdTmNb2+12bKvClxOixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCHq5nw+/+35Xx/Ss9/vx7YeHh7Gtl5eXsa21lpru91Ozt1c+tGXE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVE/8hzD4XAY3Tsej2Nbk2cEbm9vx7Ymz0xcgXMM8JWIE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVE/8lbK5I2PtdbabDZjW5O3Una73djWN+dWCnwl4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oSoz84xAFfiywlR4oQocUKUOCFKnBAlToj6A8qrR2Ne1MXsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값: 9 | 실제값: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAADyklEQVR4nO3dQVEjWhRF0ZdfCEACDhIUgAOQgIRIiJTggDhAQiREQhykR39Gdc8uu+m1hsnghMGuV8Xkbm632wJ6/vvuHwB8TZwQJU6IEidEiROi7v7w/Y/8V+7lchnd2+/3Y1un02ls6+npaWzreDyOba211sPDw+Tc5qsPvZwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6I2vzheO6PPMfw+vo6uvf8/Dy2tdvtxrbO5/PY1vV6Hdtaa63D4TA55xwD/E3ECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVF33/0D/nc6nca2Js8IrLXWfr8f25o8/fD5+Tm2Nfl3VXg5IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiMrcStlut2Nb1+t1bGuttT4+Psa2LpfL2NbkzZnD4TC2VeHlhChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQtTmdrv97vvffvm3mjwjsNZaj4+PY1svLy9jW5NnJn64zVcfejkhSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQdffdP+A7HI/H0b3tdju6x8/g5YQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocULUP3mO4Xw+j+7tdruxrff397Gt6/U6tnV/fz+2VeHlhChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IeqfvJVyPB5H997e3kb3plwul7GtyXszFV5OiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRG1ut9t3/wbgC15OiBInRIkTosQJUeKEKHFC1C/p6U7bcStm+gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값: 1 | 실제값: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAADkElEQVR4nO3dQVFjQRRA0flT7IkDkIKESIiFOIiESEAKEnBAcEAU/DGQSlhA9x04Z/l78Xpzq6v+5i3ruv4Bev7OvgBwmTghSpwQJU6IEidE3d049yv3C5xOp2GzttvtsFlPT0/DZh2Px2GzJlguffRyQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IWq5sTzXOoYvMHKVwH6/Hzbr/v5+2KyPj49hsyawjgH+J+KEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEqLvZF/gNXl5eZl/hWxwOh9lX+NG8nBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0Qt67peO796yOdsNpths87n87BZb29vw2Y9Pj4OmzXBcumjlxOixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlRd7MvMMPxeBw6b+SKhIeHh2GzfviKhOm8nBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlToj6lesYnp+fZ18BbvJyQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IepXrmPYbrdD551Op2Gz3t/fh83ie3k5IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiFrWdb12fvWQz3l9fR02a7fbDZs1cufM4XAYNmuC5dJHLydEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROibq1jACbxckKUOCFKnBAlTogSJ0SJE6L+AdEtPdhvUZ1fAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값: 4 | 실제값: 0\n"
     ]
    }
   ],
   "source": [
    "# SVM의 오답 찾기: \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "SVM.fit(X_train, y_train)\n",
    "y_pred = SVM.predict(X_test)\n",
    "y_wrong = y_test - y_pred\n",
    "\n",
    "for i in range(len(y_wrong)):\n",
    "    if y_wrong[i] != 0:\n",
    "        plt.imshow(digits.images[i].reshape(8,8), cmap = plt.cm.binary)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        print('예측값:', y_pred[i], '| 실제값:', y_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab25f539",
   "metadata": {},
   "source": [
    "**SVM 모델이 오답을 낸 데이터 이미지들은 손글씨 중에서도 선의 경계가 다소 모호한 글씨로 보인다. SVM 모델은 데이터의 경계를 구분하여 클래스를 분류하므로 위 5개 글씨 분류에 실패한 것으로 추정된다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cf9279",
   "metadata": {},
   "source": [
    "## 2. load_wine: 와인의 종류 분류\n",
    "\n",
    "### 1) 데이터 탐색\n",
    "\n",
    "* load_wine() 메서드로 불러온 데이터는 13개의 feature를 가진 178개의 샘플을 보유하고 있다.\n",
    "* 이 데이터는 와인의 종류를 'class_0', 'class_1', 'class_2' 세가지 라벨로 가지고 있는 데이터이며, feature는 'alcohol','malic_acid' 등 와인이 가질 수 있는 여러가지 특성들을 나타낸다.\n",
    "* 이 중 약 20%에 해당하는 36개 샘플을 테스트 데이터로 무작위 분리하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e26e22ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52a23f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "867f082f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a22147c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "222a6668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bf31945",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = wine.data \n",
    "label = wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "616c92b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "print(wine.feature_names)\n",
    "print(wine.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95edb8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(wine.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f71b0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 13)\n",
      "(36, 13)\n",
      "(142,)\n",
      "(36,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature, label, test_size = 0.2, random_state = 50)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de76855",
   "metadata": {},
   "source": [
    "### 2) 다양한 모델로 학습, 비교해보기\n",
    "\n",
    "* 데이터 describe에 의하면 class_0 약 33%, class_1 약 40%, class_2 약 27% 비율로 분포하고 있어 비교적 균등하게 분포되어 있는 편이므로 accuracy를 평가지표로 택했다.\n",
    "* Stochastic Gradient Descent Classifier가 가장 낮은 accuracy를, Random Forest가 가장 높은 accuracy를 보였다. 특히 SVM과 SGD 모델은 class_2를 분류하는 데에 완전히 실패하여 부적절한 모델로 판단된다. \n",
    "  * SVM과 SGD는 Desicion Tree나 Random Forest에 비해 더 복잡한 모델인만큼, wine 데이터보다 더 광범위한 데이터 문제에 적합할 것으로 예상된다.\n",
    "* Random Forest는 Desicion Tree가 혼동한 class_0과 class_1 분류를 보완하는 것으로 보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6584b366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<Classification Report of Descision Tree>\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88        13\n",
      "           1       0.87      0.93      0.90        14\n",
      "           2       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.93      0.92      0.93        36\n",
      "weighted avg       0.92      0.92      0.92        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Tree = DecisionTreeClassifier(random_state = 50)\n",
    "Tree.fit(X_train, y_train)\n",
    "y_pred = Tree.predict(X_test)\n",
    "print(\"\\t<Classification Report of Descision Tree>\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a73e7389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<Classification Report of Ramdom Forest>\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        13\n",
      "           1       1.00      0.93      0.96        14\n",
      "           2       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.98      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Forest = RandomForestClassifier(random_state = 50)\n",
    "Forest.fit(X_train, y_train)\n",
    "y_pred = Forest.predict(X_test)\n",
    "print(\"\\t<Classification Report of Ramdom Forest>\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d109d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<Classification Report of Support Vector Machine>\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.69      0.78        13\n",
      "           1       0.50      0.93      0.65        14\n",
      "           2       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.47      0.54      0.48        36\n",
      "weighted avg       0.52      0.61      0.54        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "SVM = svm.SVC()\n",
    "SVM.fit(X_train, y_train)\n",
    "y_pred = SVM.predict(X_test)\n",
    "print(\"\\t<Classification Report of Support Vector Machine>\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "919cdb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<Classification Report of Stochastic Gradient Descent Classifier>\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.54      0.70        13\n",
      "           1       0.48      1.00      0.65        14\n",
      "           2       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.58        36\n",
      "   macro avg       0.49      0.51      0.45        36\n",
      "weighted avg       0.55      0.58      0.51        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "SGD = SGDClassifier()\n",
    "SGD.fit(X_train, y_train)\n",
    "y_pred = SGD.predict(X_test)\n",
    "print(\"\\t<Classification Report of Stochastic Gradient Descent Classifier>\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "942a2f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<Classification Report of Logistic Regression>\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        13\n",
      "           1       0.88      1.00      0.93        14\n",
      "           2       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.95      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "y_pred = LR.predict(X_test)\n",
    "print(\"\\t<Classification Report of Logistic Regression>\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c35aeecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  label  \n",
       "0                            3.92   1065.0      0  \n",
       "1                            3.40   1050.0      0  \n",
       "2                            3.17   1185.0      0  \n",
       "3                            3.45   1480.0      0  \n",
       "4                            2.93    735.0      0  \n",
       "..                            ...      ...    ...  \n",
       "173                          1.74    740.0      2  \n",
       "174                          1.56    750.0      2  \n",
       "175                          1.56    835.0      2  \n",
       "176                          1.62    840.0      2  \n",
       "177                          1.60    560.0      2  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(wine.data, columns = wine.feature_names)\n",
    "df[\"label\"] = wine.target\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88094f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    3.157797\n",
      "1    2.785352\n",
      "2    1.683542\n",
      "Name: od280/od315_of_diluted_wines, dtype: float64\n",
      "label\n",
      "0    0.357077\n",
      "1    0.496573\n",
      "2    0.272111\n",
      "Name: od280/od315_of_diluted_wines, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "grouped = df['od280/od315_of_diluted_wines'].groupby(df['label']) \n",
    "print(grouped.mean())\n",
    "print(grouped.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b9d847",
   "metadata": {},
   "source": [
    "Dataframe화 하여 둘러본 결과, 'od280/od315_of_diluted_wines' feature가 label별로 차이를 보이는 경향성이 육안상으로 발견되었다. 'od280/od315_of_diluted_wines'칼럼을 라벨별로 그룹화하여 grouped 객체에 저장, 평균값을 출력해보니 각 클래스 별로 눈에 띄는 차이를 보이며, 표준편차 또한 작은 편으로 **`'od280/od315_of_diluted_wines' feature가 분류에 핵심적으로 사용되었을 가능성을 시사`**한다. 이때 class_0과 class_1의 od280/od315_of_diluted_wines 평균은 각각 약 3.2, 약 2.8로 차이가 크지 않음을 확인할 수 있는데, 이로 인해 가장 accuracy가 높았던 Random Forest에서도 class_0과 class_1을 구분하는 것에 일부 오답이 발생했을 것으로 추측된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723ba5c4",
   "metadata": {},
   "source": [
    "## 3. load_breast_cancer:  유방암 여부 진단\n",
    "\n",
    "### 1) 데이터 탐색\n",
    "\n",
    "* load_breast_cancer() 메서드로 불러온 데이터는 30개의 feature를 가진 569개의 샘플을 보유하고 있다.\n",
    "* 각 샘플은 30개의 feature와 진단 결과 label('양성'(malignant) 또는 '음성'(benign))을 갖는다.\n",
    "  * 데이터 describe에 의하면 malignant 212개, benign 357개가 존재한다. label은 텍스트 형태로 존재하지 않고 0과 1로 나타나는데, Dataframe화 하여 각 label의 갯수를 나타내어본 결과 0이 양성, 1이 음성을 나타냄을 확인할 수 있었다.\n",
    "* 이 중 약 20%에 해당하는 114개 샘플을 테스트 데이터로 무작위 분리하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04266d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b71b819c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20857e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "469db5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7031df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8631ce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = cancer.data \n",
    "label = cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb6bff67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "print(cancer.feature_names)\n",
    "print(cancer.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1cbd3e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(cancer.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c7e7abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30)\n",
      "(114, 30)\n",
      "(455,)\n",
      "(114,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature, label, test_size = 0.2, random_state = 50)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ede8ca8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  label  \n",
       "0          0.4601                  0.11890      0  \n",
       "1          0.2750                  0.08902      0  \n",
       "2          0.3613                  0.08758      0  \n",
       "3          0.6638                  0.17300      0  \n",
       "4          0.2364                  0.07678      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(cancer.data, columns = cancer.feature_names)\n",
    "df[\"label\"] = cancer.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07b48c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    357\n",
      "0    212\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec3c0b",
   "metadata": {},
   "source": [
    "### 2) 다양한 모델로 학습, 비교해보기\n",
    "\n",
    "* 이 데이터는 병의 진단 결과인만큼, 양성을 음성으로 진단했을 경우의 피해가 매우 크므로 '양성(0)'의 'recall'을 평가지표로 택했다.\n",
    "* Random Forest의 recall이 가장 높고, Support Vector Machine과 Stochastic Gradient Descent Classifier의 recall이 가장 낮았다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "234dc87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<Classification Report of Descision Tree>\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88        39\n",
      "           1       0.95      0.92      0.93        75\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.90      0.91      0.90       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Tree = DecisionTreeClassifier(random_state = 50)\n",
    "Tree.fit(X_train, y_train)\n",
    "y_pred = Tree.predict(X_test)\n",
    "print(\"\\t<Classification Report of Descision Tree>\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "366473da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<Classification Report of Ramdom Forest>\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94        39\n",
      "           1       0.97      0.96      0.97        75\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.95      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Forest = RandomForestClassifier(random_state = 50)\n",
    "Forest.fit(X_train, y_train)\n",
    "y_pred = Forest.predict(X_test)\n",
    "print(\"\\t<Classification Report of Ramdom Forest>\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "98e74c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<Classification Report of Support Vector Machine>\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92        39\n",
      "           1       0.94      0.99      0.96        75\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM = svm.SVC()\n",
    "SVM.fit(X_train, y_train)\n",
    "y_pred = SVM.predict(X_test)\n",
    "print(\"\\t<Classification Report of Support Vector Machine>\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae9dbb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<Classification Report of Stochastic Gradient Descent Classifier>\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86        39\n",
      "           1       0.93      0.92      0.93        75\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.89      0.90      0.89       114\n",
      "weighted avg       0.90      0.90      0.90       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SGD = SGDClassifier()\n",
    "SGD.fit(X_train, y_train)\n",
    "y_pred = SGD.predict(X_test)\n",
    "print(\"\\t<Classification Report of Stochastic Gradient Descent Classifier>\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1159bd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<Classification Report of Logistic Regression>\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92        39\n",
      "           1       0.95      0.97      0.96        75\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "y_pred = LR.predict(X_test)\n",
    "print(\"\\t<Classification Report of Logistic Regression>\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae16eea",
   "metadata": {},
   "source": [
    "## 회고\n",
    "\n",
    "* 알게 된 점\n",
    "  * 실제 데이터를 분류하는 문제를 처리해야 할 때, 우선 pandas 패키지의 dataframe화를 이용해 데이터를 육안으로 살피는 것만으로도 어느 정도는 분류의 감이 모델을 고르는 데에 참고로 삼을만 하다.\n",
    "\n",
    "  * digits 데이터와 같이 이미지를 분류하는 문제의 경우는 feature가 각 이미지의 픽셀 단위 하나하나를 의미하는 만큼, Desicion Tree보다는 SVM의 방법론이 더 적합하다. 반대로 분류해야 할 label 수와 feature의 수가 적을 때는 SVM이 오히려 부적절할 수도 있다.\n",
    "\n",
    "\n",
    "* 궁금한 점 \n",
    "  * SVM은 마진을 어떻게 설정하느냐에 따라 모델의 성능이 크게 바뀌는 알고리즘인데, scikit learn에서는 이 값을 사용자가 설정할 수 없게끔 되어 있는 것 같다. 자동으로 설정된다면 어떤 과정으로 설정되는 것일까?\n",
    "\n",
    "  * 우선 오류 메세지가 나오더라도 무시하고 값을 도출하는데에는 지장이 없었지만 오류 메시지가 나온 이유는 무엇이고, 특히 세 경우 모두 오류 메세지가 나온 Linear Regression 모델은 어떤 부분을 수정해야 오류를 방지할 수 있을까? \n",
    "\n",
    "\n",
    "* 모호한 점\n",
    "  * 여기서 다룬 dataset은 모두 Key-Value 구조를 가진 Bunch 타입 데이터였으므로 feature와 label, 그 이름 등을 구분하기 쉬웠지만 연습용이 아닌 실제 데이터들은 어떻게 구분할까?\n",
    "\n",
    "  * 실제로 병의 진단을 머신러닝이 수행할 경우, 양성 판정에 대한 recall이 가장 높은 모델이었다고 해도 일부 오답을 낼 수 있는데, 이 부분에 대한 보완은 어떻게 진행하면 좋을까?\n",
    "\n",
    "\n",
    "* 다짐: scikit learn과 같이 편리하게 이용할 수 있는 머신러닝 툴이 이미 개발되어 있다면, 실무적으로 빠르게 적용하기 위해서는 EDA, 시각화를 통해 적합한 방법론을 찾아보는 것이 주효할 것으로 보인다. pandas를 더 자유자재로 사용할 수 있도록 해야겠다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
